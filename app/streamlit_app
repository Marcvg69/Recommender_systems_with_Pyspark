# streamlit_app.py â€” presentation/UI only
# Assumes:
#  - ratings & movies CSVs exist (defaults can be changed via the sidebar)
#  - a saved ALS model is available at models/als_best (or the path you set)
#  - similarity tools live in src/models/similarity.py (with __init__.py files)
#    If not using a package layout, it will fallback to importing local similarity.py

import os
import sys
import pandas as pd
import streamlit as st

# Spark imports lazily to avoid app crash on environments without Spark
try:
    from pyspark.sql import SparkSession
    from pyspark.sql import functions as F
    from pyspark.ml.recommendation import ALSModel
    SPARK_OK = True
except Exception:
    SPARK_OK = False

# Import similarity: prefer package path, fallback to local file
try:
    from src.models.similarity import (
        build_item_user_matrix,
        recommend_for_new_user,
        popular_movies_baseline,
        weighted_popularity,
    )
except Exception:
    from similarity import (  # type: ignore
        build_item_user_matrix,
        recommend_for_new_user,
        popular_movies_baseline,
        weighted_popularity,
    )

# ---------- Config ----------
DEFAULT_RATINGS_CSV = os.environ.get("RATINGS_CSV", "data/sample/ratings_sample.csv")
DEFAULT_MOVIES_CSV  = os.environ.get("MOVIES_CSV",  "data/sample/movies_sample.csv")
ALS_MODEL_DIR       = os.environ.get("ALS_MODEL_DIR", "models/als_best")
TOP_N_DEFAULT       = 10

# ---------- Streamlit page ----------
st.set_page_config(page_title="Movie Recommender Demo", layout="wide")
st.title("ðŸŽ¬ Movie Recommender (PySpark ALS + Cold-Start Fallback)")

# Sidebar inputs
ratings_csv = st.sidebar.text_input("Ratings CSV", value=DEFAULT_RATINGS_CSV)
movies_csv  = st.sidebar.text_input("Movies CSV",  value=DEFAULT_MOVIES_CSV)
als_model_dir = st.sidebar.text_input("ALS model directory", value=ALS_MODEL_DIR)
top_n = st.sidebar.number_input("Top-N", min_value=1, max_value=50, value=TOP_N_DEFAULT, step=1)

# ---------- Data loading ----------
@st.cache_data(show_spinner=False)
def load_csv(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df.columns = [c.strip() for c in df.columns]
    return df

try:
    ratings_df = load_csv(ratings_csv)
    movies_df  = load_csv(movies_csv)
except Exception as e:
    st.error(f"Could not read CSV files: {e}")
    st.stop()

# Normalise IDs
if "movieId" in movies_df.columns:
    movies_df["movieId"] = pd.to_numeric(movies_df["movieId"], errors="coerce").astype("Int64")
if "userId" in ratings_df.columns:
    ratings_df["userId"] = pd.to_numeric(ratings_df["userId"], errors="coerce").astype("Int64")

# Title/ID maps
movies_df = movies_df.dropna(subset=["movieId"])
title2id = dict(zip(movies_df["title"].astype(str), movies_df["movieId"].astype(int)))
id2title = dict(zip(movies_df["movieId"].astype(int), movies_df["title"].astype(str)))

# ---------- Known user (ALS) helpers ----------
@st.cache_resource(show_spinner=False)
def get_spark() -> "SparkSession|None":
    if not SPARK_OK:
        return None
    try:
        return (
            SparkSession.builder
            .appName("RecommenderApp")
            .config("spark.ui.showConsoleProgress", "false")
            .getOrCreate()
        )
    except Exception:
        return None

@st.cache_resource(show_spinner=False)
def load_als_model(model_dir: str):
    return ALSModel.load(model_dir)

def recommend_for_known_user_als(spark, model, user_id: int, movies_csv_path: str, k: int):
    # Build a tiny users DF for the single user
    users = spark.createDataFrame([(user_id,)], ["userId"])
    recs_df = (
        model.recommendForUserSubset(users, k)
             .select("userId", F.explode("recommendations").alias("rec"))
             .select("userId", F.col("rec.movieId").alias("movieId"),
                               F.col("rec.rating").alias("score"))
    )
    movies_sdf = spark.read.option("header", True).option("inferSchema", True).csv(movies_csv_path)
    out = recs_df.join(movies_sdf, on="movieId", how="left")
    pdf = out.orderBy(F.desc("score")).toPandas()
    if "title" not in pdf.columns:
        pdf["title"] = pdf["movieId"].map(id2title)
    return pdf[["movieId", "title", "score"]]

# ---------- Cold-start artifacts ----------
@st.cache_resource(show_spinner=True)
def get_similarity_artifacts(ratings_csv_path: str):
    ratings = load_csv(ratings_csv_path)
    return build_item_user_matrix(ratings)

# ---------- UI mode switch ----------
mode = st.radio("Mode", ["Known user (ALS)", "New user (cold-start)"])

if mode == "Known user (ALS)":
    # Require Spark + saved model
    spark = get_spark()
    if spark is None:
        st.error("Spark is not available. Install PySpark or run this app in your Docker/Spark environment.")
        st.stop()

    try:
        model = load_als_model(als_model_dir)
    except Exception as e:
        st.error(
            f"ALS model not found at '{als_model_dir}'. "
            "Please train and save a model (e.g. via your train_als/tune_als pipeline) and retry."
        )
        st.stop()

    # Known users list from ratings
    known_user_ids = sorted(list(set(int(u) for u in ratings_df["userId"].dropna().unique())))
    user_id = st.selectbox("Select a known userId", known_user_ids, index=0 if known_user_ids else None)

    if st.button("Recommend (ALS)"):
        try:
            recs = recommend_for_known_user_als(spark, model, int(user_id), movies_csv, k=int(top_n))
            st.dataframe(recs.reset_index(drop=True), use_container_width=True)
        except Exception as e:
            st.error(f"ALS recommendation failed: {e}")

else:
    st.write("Pick a few movies you like to seed cold-start recommendations:")
    # Use a manageable subset to keep the multiselect responsive; users can type to search
    sample_titles = movies_df["title"].astype(str).tolist()
    seed_titles = st.multiselect("Type to search titles", sample_titles[:5000])

    seed_ids = [title2id[t] for t in seed_titles if t in title2id]

    # Build heavy artifacts once
    item_user_mat, movie2idx, idx2movie = get_similarity_artifacts(ratings_csv)

    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("Recommend (cosine similarity)"):
            if not seed_ids:
                st.warning("Select at least one liked movie.")
            else:
                rec_ids = recommend_for_new_user(
                    liked_movie_ids=seed_ids,
                    item_user_mat=item_user_mat,
                    movie2idx=movie2idx,
                    idx2movie=idx2movie,
                    top_n=int(top_n),
                    exclude=seed_ids,  # avoid echoing selected seeds
                )
                rec_df = movies_df[movies_df["movieId"].isin(rec_ids)][["movieId", "title"]].copy()
                # Preserve returned order
                order_map = {mid: i for i, mid in enumerate(rec_ids)}
                rec_df["__order"] = rec_df["movieId"].map(order_map)
                rec_df = rec_df.sort_values("__order").drop(columns="__order")
                st.subheader("Recommendations (cosine)")
                st.dataframe(rec_df, use_container_width=True)

    with col2:
        if st.button("Popular baseline"):
            pop_ids = popular_movies_baseline(ratings_df, top_n=int(top_n))
            pop_df = movies_df[movies_df["movieId"].isin(pop_ids)][["movieId", "title"]].copy()
            order_map = {mid: i for i, mid in enumerate(pop_ids)}
            pop_df["__order"] = pop_df["movieId"].map(order_map)
            pop_df = pop_df.sort_values("__order").drop(columns="__order")
            st.subheader("Popular movies (mean rating + support)")
            st.dataframe(pop_df, use_container_width=True)

    with col3:
        if st.button("Weighted popularity (IMDB-style)"):
            wr_ids = weighted_popularity(ratings_df, top_n=int(top_n))
            wr_df = movies_df[movies_df["movieId"].isin(wr_ids)][["movieId", "title"]].copy()
            order_map = {mid: i for i, mid in enumerate(wr_ids)}
            wr_df["__order"] = wr_df["movieId"].map(order_map)
            wr_df = wr_df.sort_values("__order").drop(columns="__order")
            st.subheader("Popular movies (weighted)")
            st.dataframe(wr_df, use_container_width=True)

st.caption("Tip: set RATINGS_CSV, MOVIES_CSV, ALS_MODEL_DIR via environment variables if needed.")
