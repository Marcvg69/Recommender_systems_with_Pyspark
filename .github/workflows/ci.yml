name: CI

on:
  push:
  pull_request:

jobs:
  build-test-train:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Set up Java (for PySpark)
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "17"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install app dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install "pyspark>=3.4,<3.6" pandas numpy streamlit
          fi

      - name: Install dev tools (ruff & pytest)
        run: |
          pip install "ruff==0.6.8" "pytest>=7,<9"

      - name: Tool versions (debug)
        run: |
          which python; python -V
          pip -V
          python -m ruff --version

      - name: Lint
        run: |
          python -m ruff check .

      - name: Unit tests
        run: pytest -q

      - name: Generate tiny sample data
        run: |
          python - << 'PY'
          import os, csv, random, time, pathlib
          out = pathlib.Path("data/sample")
          out.mkdir(parents=True, exist_ok=True)
          movies=[(i, f"Movie {i}", "Drama|Action") for i in range(1,301)]
          with open(out/"movies_sample.csv","w",newline="") as f:
              w=csv.writer(f); w.writerow(["movieId","title","genres"]); w.writerows(movies)
          rows=[]; rng=random.Random(42)
          for u in range(1,51):
              for _ in range(15):
                  rows.append([u, rng.randint(1,300), rng.choice([2.5,3,3.5,4,4.5,5]), int(time.time())])
          with open(out/"ratings_sample.csv","w",newline="") as f:
              w=csv.writer(f); w.writerow(["userId","movieId","rating","timestamp"]); w.writerows(rows)
          print("Wrote sample CSVs to", out)
          PY

      - name: Show source tree (debug)
        run: |
          pwd
          ls -la
          ls -la src || true
          ls -la src/models || true
          echo "--- tracked files (first 200) ---"
          git ls-files | sed -n '1,200p'

      - name: Smoke train (fast) â€” choose entrypoint
        env:
          SPARK_DRIVER_MEMORY: 1g
        run: |
          set -euxo pipefail
          ENTRY=""
          if [[ -f "src/models/tune_als.py" ]]; then
            ENTRY="src/models/tune_als.py"
          elif [[ -f "src/models/train_als.py" ]]; then
            ENTRY="src/models/train_als.py"
          else
            echo "No training entry point found in src/models (expected tune_als.py or train_als.py)."
            exit 1
          fi
          echo "Using entrypoint: $ENTRY"
          python "$ENTRY" \
            --ratings_csv data/sample/ratings_sample.csv \
            --model_out models/als_best \
            --ranks 8,16 \
            --regParams 0.05 \
            --maxIter 2 \
            --sims_topN 5 \
            --sims_method driver \
            --driver_batch 64 \
            --shuffle_partitions 8

      - name: Upload artifacts (model + sims)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: als_smoke_artifacts
          path: |
            models/als_best/**
            data/processed/item_sims/**
          if-no-files-found: ignore
